{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EX1G</th>\n",
       "      <th>EX2G</th>\n",
       "      <th>A1G</th>\n",
       "      <th>A2G</th>\n",
       "      <th>C1G</th>\n",
       "      <th>C2G</th>\n",
       "      <th>ES1G</th>\n",
       "      <th>ES2G</th>\n",
       "      <th>O1G</th>\n",
       "      <th>O2G</th>\n",
       "      <th>CONDITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EX1G  EX2G  A1G  A2G  C1G  C2G  ES1G  ES2G  O1G  O2G CONDITION\n",
       "0     4     4    4    4    4    5     4     4    4    4         H\n",
       "1     4     2    2    4    4    5     3     4    4    4         H\n",
       "2     4     2    2    4    4    4     3     4    4    4         H\n",
       "3     4     2    2    4    2    4     5     5    4    2         H\n",
       "4     3     2    3    4    5    5     4     4    5    5         H"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('BF_df_CTU.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real = data.iloc[:n//2,:-1]\n",
    "x_fake = data.iloc[n//2:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice([0,1,2], size=n//2, p=[0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real_train = x_real[index==0]\n",
    "x_real_val = x_real[index==1]\n",
    "x_real_test = x_real[index==2]\n",
    "\n",
    "x_fake_train = x_fake[index==0]\n",
    "x_fake_val = x_fake[index==1]\n",
    "x_fake_test = x_fake[index==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive approach\n",
    "\n",
    "All the proposed method should outperform the trivial strategy of subtracting to each subject faked response the average of the difference, across all subjects, among faked and honest response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4906668983737246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train = (x_fake_train.to_numpy() - x_real_train.to_numpy()).mean(axis=0)\n",
    "test_mse = (((x_fake_test.subtract(mean_train)).to_numpy() - x_real_test.to_numpy())**2).mean()\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_1 = 6\n",
    "dim_2 = 3\n",
    "\n",
    "input_vector = tf.keras.layers.Input(shape=(10,))\n",
    "\n",
    "# Define the encoder\n",
    "hidden_1 = tf.keras.layers.Dense(dim_1, activation='sigmoid')(input_vector)\n",
    "encoded = tf.keras.layers.Dense(dim_2, activation='sigmoid')(hidden_1)\n",
    "\n",
    "# ...and the decoder...\n",
    "hidden_2 = tf.keras.layers.Dense(dim_1, activation='sigmoid')(encoded)\n",
    "decoded = tf.keras.layers.Dense(10, activation='linear')(hidden_2)\n",
    "\n",
    "# and finally the autoencoder\n",
    "autoencoder = tf.keras.models.Model(inputs=input_vector, outputs=decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                70        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 12.2255 - val_loss: 12.7404\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 12.0444 - val_loss: 12.5563\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.8636 - val_loss: 12.3736\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.6852 - val_loss: 12.1920\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 11.5088 - val_loss: 12.0114\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.3323 - val_loss: 11.8325\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.1573 - val_loss: 11.6552\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.9835 - val_loss: 11.4797\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.8132 - val_loss: 11.3054\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.6418 - val_loss: 11.1335\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.4752 - val_loss: 10.9628\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.3080 - val_loss: 10.7942\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.1439 - val_loss: 10.6273\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.9797 - val_loss: 10.4625\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8186 - val_loss: 10.2987\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.6585 - val_loss: 10.1356\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.4984 - val_loss: 9.9734\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.3396 - val_loss: 9.8112\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.1803 - val_loss: 9.6490\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.0209 - val_loss: 9.4865\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8619 - val_loss: 9.3237\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.7020 - val_loss: 9.1621\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5435 - val_loss: 9.0020\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.3867 - val_loss: 8.8442\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2334 - val_loss: 8.6886\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.0801 - val_loss: 8.5366\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9325 - val_loss: 8.3861\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7863 - val_loss: 8.2375\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.6418 - val_loss: 8.0909\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.5003 - val_loss: 7.9458\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3594 - val_loss: 7.8028\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2193 - val_loss: 7.6624\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0829 - val_loss: 7.5236\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.9482 - val_loss: 7.3863\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8146 - val_loss: 7.2508\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6832 - val_loss: 7.1171\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5537 - val_loss: 6.9852\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.4244 - val_loss: 6.8558\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.2998 - val_loss: 6.7273\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1759 - val_loss: 6.6007\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.0538 - val_loss: 6.4759\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.9335 - val_loss: 6.3532\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8143 - val_loss: 6.2332\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6981 - val_loss: 6.1150\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5839 - val_loss: 5.9987\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4720 - val_loss: 5.8841\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.3622 - val_loss: 5.7714\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.2534 - val_loss: 5.6610\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1471 - val_loss: 5.5527\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.0431 - val_loss: 5.4463\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9412 - val_loss: 5.3418\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8413 - val_loss: 5.2393\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7422 - val_loss: 5.1394\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6468 - val_loss: 5.0413\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5533 - val_loss: 4.9450\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4615 - val_loss: 4.8506\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3714 - val_loss: 4.7583\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2830 - val_loss: 4.6680\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1972 - val_loss: 4.5795\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1128 - val_loss: 4.4932\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0308 - val_loss: 4.4085\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9505 - val_loss: 4.3259\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8720 - val_loss: 4.2451\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7954 - val_loss: 4.1662\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7206 - val_loss: 4.0891\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6472 - val_loss: 4.0138\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5770 - val_loss: 3.9398\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5067 - val_loss: 3.8680\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4396 - val_loss: 3.7975\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3729 - val_loss: 3.7291\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3080 - val_loss: 3.6625\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2462 - val_loss: 3.5969\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1842 - val_loss: 3.5332\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1242 - val_loss: 3.4713\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0671 - val_loss: 3.4102\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0090 - val_loss: 3.3514\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9540 - val_loss: 3.2937\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.9006 - val_loss: 3.2371\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8484 - val_loss: 3.1818\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7959 - val_loss: 3.1285\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.7466 - val_loss: 3.0760\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6984 - val_loss: 3.0247\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6504 - val_loss: 2.9749\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6040 - val_loss: 2.9265\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.5594 - val_loss: 2.8789\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.5159 - val_loss: 2.8324\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4722 - val_loss: 2.7876\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4308 - val_loss: 2.7437\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3904 - val_loss: 2.7008\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3513 - val_loss: 2.6589\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.3127 - val_loss: 2.6180\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2752 - val_loss: 2.5780\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2381 - val_loss: 2.5394\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2031 - val_loss: 2.5015\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1691 - val_loss: 2.4643\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1344 - val_loss: 2.4285\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1016 - val_loss: 2.3935\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0699 - val_loss: 2.3594\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.0388 - val_loss: 2.3260\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0087 - val_loss: 2.2934\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9793 - val_loss: 2.2616\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9506 - val_loss: 2.2307\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9223 - val_loss: 2.2007\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8956 - val_loss: 2.1714\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8690 - val_loss: 2.1430\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.8433 - val_loss: 2.1152\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8180 - val_loss: 2.0885\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7943 - val_loss: 2.0620\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7704 - val_loss: 2.0364\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7478 - val_loss: 2.0112\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7254 - val_loss: 1.9867\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7034 - val_loss: 1.9631\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6825 - val_loss: 1.9401\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6620 - val_loss: 1.9178\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6424 - val_loss: 1.8959\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6228 - val_loss: 1.8747\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6044 - val_loss: 1.8538\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5861 - val_loss: 1.8338\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5681 - val_loss: 1.8144\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.5514 - val_loss: 1.7953\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5341 - val_loss: 1.7771\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5185 - val_loss: 1.7590\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5028 - val_loss: 1.7416\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4877 - val_loss: 1.7245\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4730 - val_loss: 1.7079\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4586 - val_loss: 1.6920\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4452 - val_loss: 1.6763\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4314 - val_loss: 1.6614\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4187 - val_loss: 1.6467\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4060 - val_loss: 1.6327\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3940 - val_loss: 1.6189\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3824 - val_loss: 1.6056\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3710 - val_loss: 1.5926\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3599 - val_loss: 1.5800\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3494 - val_loss: 1.5679\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3392 - val_loss: 1.5559\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3292 - val_loss: 1.5446\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3198 - val_loss: 1.5335\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3105 - val_loss: 1.5225\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3017 - val_loss: 1.5122\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2927 - val_loss: 1.5023\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2847 - val_loss: 1.4926\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2766 - val_loss: 1.4833\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2688 - val_loss: 1.4742\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2615 - val_loss: 1.4654\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2545 - val_loss: 1.4568\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2472 - val_loss: 1.4488\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2406 - val_loss: 1.4410\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2344 - val_loss: 1.4333\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2283 - val_loss: 1.4257\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2222 - val_loss: 1.4186\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2165 - val_loss: 1.4117\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2111 - val_loss: 1.4049\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2058 - val_loss: 1.3984\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2006 - val_loss: 1.3923\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1960 - val_loss: 1.3863\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1911 - val_loss: 1.3806\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1867 - val_loss: 1.3749\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1824 - val_loss: 1.3695\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1782 - val_loss: 1.3641\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1742 - val_loss: 1.3591\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1704 - val_loss: 1.3544\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1668 - val_loss: 1.3498\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1633 - val_loss: 1.3451\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1598 - val_loss: 1.3409\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1566 - val_loss: 1.3368\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1535 - val_loss: 1.3327\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1505 - val_loss: 1.3290\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1477 - val_loss: 1.3254\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1449 - val_loss: 1.3217\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1423 - val_loss: 1.3183\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1398 - val_loss: 1.3149\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1373 - val_loss: 1.3117\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1350 - val_loss: 1.3086\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1329 - val_loss: 1.3057\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1308 - val_loss: 1.3029\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1287 - val_loss: 1.3003\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.1270 - val_loss: 1.2976\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1249 - val_loss: 1.2950\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1232 - val_loss: 1.2925\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1216 - val_loss: 1.2902\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1199 - val_loss: 1.2881\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1184 - val_loss: 1.2858\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1170 - val_loss: 1.2837\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1156 - val_loss: 1.2817\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1142 - val_loss: 1.2797\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1129 - val_loss: 1.2778\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1117 - val_loss: 1.2759\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1105 - val_loss: 1.2744\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1095 - val_loss: 1.2726\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1085 - val_loss: 1.2709\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1073 - val_loss: 1.2694\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1064 - val_loss: 1.2679\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1055 - val_loss: 1.2664\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1046 - val_loss: 1.2652\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1038 - val_loss: 1.2638\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1030 - val_loss: 1.2626\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1022 - val_loss: 1.2613\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1015 - val_loss: 1.2604\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1008 - val_loss: 1.2593\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1001 - val_loss: 1.2584\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0996 - val_loss: 1.2577\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0990 - val_loss: 1.2566\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0984 - val_loss: 1.2556\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0979 - val_loss: 1.2547\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0973 - val_loss: 1.2537\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0969 - val_loss: 1.2528\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0964 - val_loss: 1.2520\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0960 - val_loss: 1.2512\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0956 - val_loss: 1.2505\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0952 - val_loss: 1.2498\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0948 - val_loss: 1.2492\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0944 - val_loss: 1.2484\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0941 - val_loss: 1.2477\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0938 - val_loss: 1.2472\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0935 - val_loss: 1.2464\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0933 - val_loss: 1.2459\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0930 - val_loss: 1.2453\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0927 - val_loss: 1.2452\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0925 - val_loss: 1.2447\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0922 - val_loss: 1.2441\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0920 - val_loss: 1.2436\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0918 - val_loss: 1.2432\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0916 - val_loss: 1.2429\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0915 - val_loss: 1.2424\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0913 - val_loss: 1.2419\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0911 - val_loss: 1.2415\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0910 - val_loss: 1.2411\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0907 - val_loss: 1.2408\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0906 - val_loss: 1.2405\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0905 - val_loss: 1.2403\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0904 - val_loss: 1.2398\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0902 - val_loss: 1.2394\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0902 - val_loss: 1.2393\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0901 - val_loss: 1.2389\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0899 - val_loss: 1.2386\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0898 - val_loss: 1.2386\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0898 - val_loss: 1.2387\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0896 - val_loss: 1.2384\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0896 - val_loss: 1.2380\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0896 - val_loss: 1.2377\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0894 - val_loss: 1.2375\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0894 - val_loss: 1.2373\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0894 - val_loss: 1.2372\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0893 - val_loss: 1.2369\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0892 - val_loss: 1.2369\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0891 - val_loss: 1.2368\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0891 - val_loss: 1.2369\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0891 - val_loss: 1.2367\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0891 - val_loss: 1.2362\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0890 - val_loss: 1.2362\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0890 - val_loss: 1.2359\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0889 - val_loss: 1.2360\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0889 - val_loss: 1.2360\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0888 - val_loss: 1.2357\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0888 - val_loss: 1.2356\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0888 - val_loss: 1.2357\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0888 - val_loss: 1.2355\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0887 - val_loss: 1.2354\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0887 - val_loss: 1.2354\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0887 - val_loss: 1.2354\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0887 - val_loss: 1.2355\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0887 - val_loss: 1.2354\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0886 - val_loss: 1.2352\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0886 - val_loss: 1.2352\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0886 - val_loss: 1.2350\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0886 - val_loss: 1.2348\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0886 - val_loss: 1.2347\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0886 - val_loss: 1.2348\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0886 - val_loss: 1.2348\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0886 - val_loss: 1.2347\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0885 - val_loss: 1.2346\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0885 - val_loss: 1.2346\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2345\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2346\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2344\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2342\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0885 - val_loss: 1.2343\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2339\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2340\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2342\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0884 - val_loss: 1.2341\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0884 - val_loss: 1.2340\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2340\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.2340\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.2339\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.2338\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2336\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0885 - val_loss: 1.2337\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0884 - val_loss: 1.2337\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2337\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2338\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.2336\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0885 - val_loss: 1.2334\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.2334\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0884 - val_loss: 1.2335\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2336\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0884 - val_loss: 1.2337\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0884 - val_loss: 1.2338\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0884 - val_loss: 1.2337\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_fake_train, x_real_train, epochs=300, shuffle=True, validation_data=(x_fake_val, x_real_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.figure(figsize=(10,6))\n",
    "  plt.plot(history.epoch,history.history['loss'])\n",
    "  plt.plot(history.epoch,history.history['val_loss'])\n",
    "  plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.1923\n",
      "test mse: 1.19227\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)\n",
    "\n",
    "scores = autoencoder.evaluate(x_fake_test, x_real_test, verbose=2)\n",
    "print(\"test mse: %.5f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023E3FE320D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.192271921293912"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse = ((autoencoder.predict(x_fake_test) - x_real_test.to_numpy())**2).mean()\n",
    "test_mse"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9eeba5bd99ea3724a08722bac81bf50ab3a3f7a3f1a19e1997b49231e213487"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
